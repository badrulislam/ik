{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.7.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit (conda)"
    },
    "interpreter": {
      "hash": "a058c225e0b85d462dc242efc5fd83c59264e089b0b6ce99cdb47029e80f46cc"
    },
    "colab": {
      "name": "badrul_ik_ml_module5-pre-class-question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4iPOpqFMf0K"
      },
      "source": [
        "# Environment Setup (Python)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpgRXY-xMgJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43307a00-3248-4490-cde7-59d589437629"
      },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "ğŸ“¦ Installing...\n",
            "ğŸ“Œ Adjusting configuration...\n",
            "ğŸ©¹ Patching environment...\n",
            "â² Done in 0:00:33\n",
            "ğŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUJAtdAqMrNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff0be1b-785a-428a-d24b-1b2b7e634444"
      },
      "source": [
        "%%writefile environment.yml\n",
        "channels:\n",
        "  - default\n",
        "  - conda-forge\n",
        "  - pytorch\n",
        "dependencies:\n",
        "  - pip>20.1\n",
        "  - python>=3.7,<3.9\n",
        "  - pytorch=1.8.0\n",
        "  - torchtext=0.9\n",
        "  - pip:\n",
        "    - torch==1.8\n",
        "    - transformers==4.11.0\n",
        "    - torchmetrics==0.5.1\n",
        "    - spacy==3.1.3\n",
        "    - pandas==1.3.3\n",
        "    - pytorch_lightning==1.4.8\n",
        "    - azureml-core>=1.31.0\n",
        "    - azureml-mlflow>=1.31.0\n",
        "    - tqdm>=4.59,<4.60\n",
        "    - matplotlib==3.4.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing environment.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-BO2AOkMxeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f735d2-d2b7-4553-e5cb-0f82aef26eb3"
      },
      "source": [
        "!conda env update -n base -f environment.yml"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.9.2\n",
            "  latest version: 4.12.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "sleef-3.5.1          | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.68it/s]\n",
            "future-0.18.2        | 713 KB    | : 100% 1.0/1 [00:00<00:00,  3.13it/s]\n",
            "openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.99it/s]\n",
            "cudatoolkit-11.1.1   | 1.20 GB   | : 100% 1.0/1 [03:14<00:00, 194.80s/it]              \n",
            "llvm-openmp-12.0.1   | 2.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.82it/s]\n",
            "libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 26.03it/s]\n",
            "numpy-1.21.1         | 6.1 MB    | : 100% 1.0/1 [00:01<00:00,  1.59s/it]               \n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 23.76it/s]\n",
            "_openmp_mutex-4.5    | 5 KB      | : 100% 1.0/1 [00:00<00:00, 28.86it/s]\n",
            "certifi-2021.10.8    | 145 KB    | : 100% 1.0/1 [00:00<00:00, 14.12it/s]\n",
            "typing_extensions-4. | 29 KB     | : 100% 1.0/1 [00:00<00:00, 20.53it/s]\n",
            "pytorch-1.8.0        | 43.3 MB   | : 100% 1.0/1 [00:11<00:00, 11.44s/it]               \n",
            "pip-22.0.4           | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.93it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 25.60it/s]\n",
            "libprotobuf-3.16.0   | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.68it/s]\n",
            "python_abi-3.7       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 26.27it/s]\n",
            "torchtext-0.9.0      | 11.4 MB   | : 100% 1.0/1 [00:03<00:00,  3.45s/it]\n",
            "mkl-2020.4           | 215.6 MB  | : 100% 1.0/1 [00:48<00:00, 48.56s/it]               \n",
            "ca-certificates-2021 | 139 KB    | : 100% 1.0/1 [00:00<00:00, 11.12it/s]\n",
            "ninja-1.10.2         | 2.4 MB    | : 100% 1.0/1 [00:00<00:00,  2.06it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| Ran pip subprocess with arguments:\n",
            "['/usr/local/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/condaenv.2_o0cp83.requirements.txt']\n",
            "Pip subprocess output:\n",
            "Collecting torch==1.8\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 735.5/735.5 MB 2.0 MB/s eta 0:00:00\n",
            "Collecting transformers==4.11.0\n",
            "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.9/2.9 MB 45.4 MB/s eta 0:00:00\n",
            "Collecting torchmetrics==0.5.1\n",
            "  Downloading torchmetrics-0.5.1-py3-none-any.whl (282 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 283.0/283.0 KB 7.8 MB/s eta 0:00:00\n",
            "Collecting spacy==3.1.3\n",
            "  Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.9/5.9 MB 56.1 MB/s eta 0:00:00\n",
            "Collecting pandas==1.3.3\n",
            "  Downloading pandas-1.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.3/11.3 MB 60.4 MB/s eta 0:00:00\n",
            "Collecting pytorch_lightning==1.4.8\n",
            "  Downloading pytorch_lightning-1.4.8-py3-none-any.whl (924 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 924.0/924.0 KB 21.8 MB/s eta 0:00:00\n",
            "Collecting azureml-core>=1.31.0\n",
            "  Downloading azureml_core-1.40.0-py3-none-any.whl (2.7 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.7/2.7 MB 40.0 MB/s eta 0:00:00\n",
            "Collecting azureml-mlflow>=1.31.0\n",
            "  Downloading azureml_mlflow-1.40.0-py3-none-any.whl (46 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 46.4/46.4 KB 5.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm<4.60,>=4.59 in /usr/local/lib/python3.7/site-packages (from -r /content/condaenv.2_o0cp83.requirements.txt (line 9)) (4.59.0)\n",
            "Collecting matplotlib==3.4.3\n",
            "  Downloading matplotlib-3.4.3-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.3/10.3 MB 59.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/site-packages (from torch==1.8->-r /content/condaenv.2_o0cp83.requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch==1.8->-r /content/condaenv.2_o0cp83.requirements.txt (line 1)) (1.21.1)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 596.3/596.3 KB 14.5 MB/s eta 0:00:00\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 749.6/749.6 KB 28.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from transformers==4.11.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 2)) (2.25.1)\n",
            "Collecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.8/40.8 KB 4.0 MB/s eta 0:00:00\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.3/3.3 MB 45.1 MB/s eta 0:00:00\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 895.2/895.2 KB 31.8 MB/s eta 0:00:00\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 77.9/77.9 KB 9.0 MB/s eta 0:00:00\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.1/10.1 MB 66.4 MB/s eta 0:00:00\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 42.8/42.8 KB 4.8 MB/s eta 0:00:00\n",
            "Collecting preshed<3.1.0,>=3.0.2\n",
            "  Downloading preshed-3.0.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (125 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 125.9/125.9 KB 15.4 MB/s eta 0:00:00\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting wasabi<1.1.0,>=0.8.1\n",
            "  Downloading wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
            "Collecting thinc<8.1.0,>=8.0.9\n",
            "  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 653.3/653.3 KB 3.4 MB/s eta 0:00:00\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 452.0/452.0 KB 9.4 MB/s eta 0:00:00\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.1-py3-none-any.whl (132 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 132.6/132.6 KB 15.1 MB/s eta 0:00:00\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from spacy==3.1.3->-r /content/condaenv.2_o0cp83.requirements.txt (line 4)) (49.6.0.post20210108)\n",
            "Collecting blis<0.8.0,>=0.4.0\n",
            "  Downloading blis-0.7.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 9.9/9.9 MB 65.7 MB/s eta 0:00:00\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting typing-extensions\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 247.7/247.7 KB 10.9 MB/s eta 0:00:00\n",
            "Collecting pytz>=2017.3\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 503.5/503.5 KB 12.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/site-packages (from pytorch_lightning==1.4.8->-r /content/condaenv.2_o0cp83.requirements.txt (line 6)) (0.18.2)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 136.1/136.1 KB 13.6 MB/s eta 0:00:00\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting tensorboard>=2.2.0\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.8/5.8 MB 59.1 MB/s eta 0:00:00\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.3/4.3 MB 34.3 MB/s eta 0:00:00\n",
            "Collecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 32.9 MB/s eta 0:00:00\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 98.0/98.0 KB 4.5 MB/s eta 0:00:00\n",
            "Collecting docker<6.0.0\n",
            "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 146.2/146.2 KB 16.3 MB/s eta 0:00:00\n",
            "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
            "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 141.4/141.4 KB 15.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: urllib3<=1.26.7,>=1.23 in /usr/local/lib/python3.7/site-packages (from azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (1.26.3)\n",
            "Collecting azure-mgmt-containerregistry<9.0.0,>=8.2.0\n",
            "  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 928.0/928.0 KB 20.9 MB/s eta 0:00:00\n",
            "Collecting msrest<1.0.0,>=0.5.1\n",
            "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 85.2/85.2 KB 10.5 MB/s eta 0:00:00\n",
            "Collecting azure-mgmt-resource<21.0.0,>=15.0.0\n",
            "  Downloading azure_mgmt_resource-20.1.0-py3-none-any.whl (2.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.3/2.3 MB 46.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pyopenssl<22.0.0 in /usr/local/lib/python3.7/site-packages (from azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (20.0.1)\n",
            "Collecting jmespath<1.0.0\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting msal<2.0.0,>=1.15.0\n",
            "  Downloading msal-1.17.0-py2.py3-none-any.whl (79 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 79.3/79.3 KB 8.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0 in /usr/local/lib/python3.7/site-packages (from azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (3.4.5)\n",
            "Collecting azure-mgmt-keyvault<10.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 412.4/412.4 KB 14.1 MB/s eta 0:00:00\n",
            "Collecting azure-common<2.0.0,>=1.1.12\n",
            "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
            "Collecting PyJWT<3.0.0\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting jsonpickle<3.0.0\n",
            "  Downloading jsonpickle-2.1.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
            "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 94.5/94.5 KB 12.4 MB/s eta 0:00:00\n",
            "Collecting contextlib2<22.0.0\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting azure-core<1.22\n",
            "  Downloading azure_core-1.21.1-py2.py3-none-any.whl (178 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178.1/178.1 KB 19.6 MB/s eta 0:00:00\n",
            "Collecting humanfriendly<11.0,>=4.7\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 86.8/86.8 KB 10.7 MB/s eta 0:00:00\n",
            "Collecting SecretStorage<4.0.0\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting knack~=0.9.0\n",
            "  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 59.8/59.8 KB 6.4 MB/s eta 0:00:00\n",
            "Collecting pathspec<1.0.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting msrestazure<=0.6.4,>=0.4.33\n",
            "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.5/40.5 KB 4.2 MB/s eta 0:00:00\n",
            "Collecting msal-extensions<0.4,>=0.3.0\n",
            "  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting backports.tempfile\n",
            "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting azure-mgmt-storage<20.0.0,>=16.0.0\n",
            "  Downloading azure_mgmt_storage-19.1.0-py3-none-any.whl (1.8 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 MB 37.0 MB/s eta 0:00:00\n",
            "Collecting pkginfo\n",
            "  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
            "Collecting ndg-httpsclient<=0.5.1\n",
            "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
            "Collecting paramiko<3.0.0,>=2.0.8\n",
            "  Downloading paramiko-2.10.3-py2.py3-none-any.whl (211 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 211.9/211.9 KB 21.8 MB/s eta 0:00:00\n",
            "Collecting adal<=1.2.7,>=1.2.0\n",
            "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 55.5/55.5 KB 6.0 MB/s eta 0:00:00\n",
            "Collecting argcomplete<2.0\n",
            "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
            "Collecting mlflow-skinny\n",
            "  Downloading mlflow_skinny-1.24.0-py3-none-any.whl (3.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.3/3.3 MB 45.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/site-packages (from azure-core<1.22->azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (1.15.0)\n",
            "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
            "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0->azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (1.14.5)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 54.3/54.3 KB 6.0 MB/s eta 0:00:00\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 25.1 MB/s eta 0:00:00\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 24.9 MB/s eta 0:00:00\n",
            "Collecting tabulate\n",
            "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
            "Collecting portalocker<3,>=1.0\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting isodate>=0.6.0\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 41.7/41.7 KB 4.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (2021.10.8)\n",
            "Collecting requests-oauthlib>=0.5.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting pyasn1>=0.1.1\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 77.1/77.1 KB 9.3 MB/s eta 0:00:00\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 856.7/856.7 KB 18.5 MB/s eta 0:00:00\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.9/61.9 KB 7.1 MB/s eta 0:00:00\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 58.6/58.6 KB 6.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->transformers==4.11.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->transformers==4.11.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 2)) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/site-packages (from requests->transformers==4.11.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 2)) (1.7.1)\n",
            "Collecting jeepney>=0.6\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 48.4/48.4 KB 5.1 MB/s eta 0:00:00\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 156.5/156.5 KB 18.8 MB/s eta 0:00:00\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.44.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.3/4.3 MB 56.4 MB/s eta 0:00:00\n",
            "Collecting protobuf>=3.6.0\n",
            "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.0/1.0 MB 33.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.4.8->-r /content/condaenv.2_o0cp83.requirements.txt (line 6)) (0.36.2)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 781.3/781.3 KB 27.0 MB/s eta 0:00:00\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.8/97.8 KB 9.9 MB/s eta 0:00:00\n",
            "Collecting absl-py>=0.4\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 126.7/126.7 KB 14.8 MB/s eta 0:00:00\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.1.1-py3-none-any.whl (224 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 224.7/224.7 KB 22.1 MB/s eta 0:00:00\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.9/4.9 MB 57.9 MB/s eta 0:00:00\n",
            "Collecting click<9.0.0,>=7.1.1\n",
            "  Downloading click-8.1.2-py3-none-any.whl (96 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 96.6/96.6 KB 11.3 MB/s eta 0:00:00\n",
            "Collecting backports.weakref\n",
            "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 181.2/181.2 KB 20.5 MB/s eta 0:00:00\n",
            "Collecting cloudpickle\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.16.6.tar.gz (62 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.2/62.2 KB 6.7 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 307.0/307.0 KB 12.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<37.0.0->azureml-core>=1.31.0->-r /content/condaenv.2_o0cp83.requirements.txt (line 7)) (2.20)\n",
            "Collecting oauthlib>=3.1.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 151.5/151.5 KB 16.0 MB/s eta 0:00:00\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.1/63.1 KB 7.3 MB/s eta 0:00:00\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 155.3/155.3 KB 756.1 kB/s eta 0:00:00\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 60.6/60.6 KB 7.0 MB/s eta 0:00:00\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 144.8/144.8 KB 18.2 MB/s eta 0:00:00\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 271.8/271.8 KB 7.6 MB/s eta 0:00:00\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 94.8/94.8 KB 8.9 MB/s eta 0:00:00\n",
            "Collecting charset-normalizer<3.0,>=2.0\n",
            "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py): started\n",
            "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.16.6-py3-none-any.whl size=112628 sha256=4ad72f46beb4fcea48ddccc7228e2fb53fcd12299a4922f1dbd618ac505d223f\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/c1/f8/d75a22e789ab6a4dff11f18338c3af4360189aa371295cc934\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: wasabi, typing-extensions, tokenizers, tensorboard-plugin-wit, tabulate, pytz, pyasn1, pkginfo, murmurhash, cymem, backports.weakref, azure-common, zipp, werkzeug, websocket-client, torch, tensorboard-data-server, spacy-legacy, smmap, smart-open, rsa, regex, pyyaml, python-dateutil, pyparsing, PyJWT, pygments, pyDeprecate, pydantic, pyasn1-modules, protobuf, preshed, portalocker, pillow, pathspec, oauthlib, multidict, MarkupSafe, kiwisolver, joblib, jmespath, jeepney, isodate, humanfriendly, grpcio, fsspec, frozenlist, filelock, entrypoints, cycler, contextlib2, cloudpickle, charset-normalizer, cachetools, blis, backports.tempfile, attrs, asynctest, async-timeout, absl-py, yarl, requests-oauthlib, pynacl, pandas, packaging, matplotlib, jinja2, importlib-metadata, google-auth, gitdb, docker, catalogue, bcrypt, azure-core, aiosignal, torchmetrics, srsly, SecretStorage, paramiko, msrest, markdown, jsonpickle, huggingface-hub, google-auth-oauthlib, gitpython, click, azure-mgmt-core, argcomplete, aiohttp, adal, typer, thinc, tensorboard, sacremoses, ndg-httpsclient, msrestazure, msal, knack, databricks-cli, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, transformers, pytorch_lightning, pathy, msal-extensions, mlflow-skinny, azure-mgmt-authorization, azure-graphrbac, spacy, azureml-core, azureml-mlflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.1.1\n",
            "    Uninstalling typing_extensions-4.1.1:\n",
            "      Successfully uninstalled typing_extensions-4.1.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.8.0.post3\n",
            "    Uninstalling torch-1.8.0.post3:\n",
            "      Successfully uninstalled torch-1.8.0.post3\n",
            "Successfully installed MarkupSafe-2.1.1 PyJWT-2.3.0 SecretStorage-3.3.1 absl-py-1.0.0 adal-1.2.7 aiohttp-3.8.1 aiosignal-1.2.0 argcomplete-1.12.3 async-timeout-4.0.2 asynctest-0.13.0 attrs-21.4.0 azure-common-1.1.28 azure-core-1.21.1 azure-graphrbac-0.61.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-core-1.3.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-resource-20.1.0 azure-mgmt-storage-19.1.0 azureml-core-1.40.0 azureml-mlflow-1.40.0 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.2.0 blis-0.7.7 cachetools-5.0.0 catalogue-2.0.7 charset-normalizer-2.0.12 click-8.1.2 cloudpickle-2.0.0 contextlib2-21.6.0 cycler-0.11.0 cymem-2.0.6 databricks-cli-0.16.6 docker-5.0.3 entrypoints-0.4 filelock-3.6.0 frozenlist-1.3.0 fsspec-2022.3.0 gitdb-4.0.9 gitpython-3.1.27 google-auth-2.6.2 google-auth-oauthlib-0.4.6 grpcio-1.44.0 huggingface-hub-0.5.1 humanfriendly-10.0 importlib-metadata-4.11.3 isodate-0.6.1 jeepney-0.8.0 jinja2-3.1.1 jmespath-0.10.0 joblib-1.1.0 jsonpickle-2.1.0 kiwisolver-1.4.2 knack-0.9.0 markdown-3.3.6 matplotlib-3.4.3 mlflow-skinny-1.24.0 msal-1.17.0 msal-extensions-0.3.1 msrest-0.6.21 msrestazure-0.6.4 multidict-6.0.2 murmurhash-1.0.6 ndg-httpsclient-0.5.1 oauthlib-3.2.0 packaging-21.3 pandas-1.3.3 paramiko-2.10.3 pathspec-0.9.0 pathy-0.6.1 pillow-9.1.0 pkginfo-1.8.2 portalocker-2.4.0 preshed-3.0.6 protobuf-3.20.0 pyDeprecate-0.3.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydantic-1.8.2 pygments-2.11.2 pynacl-1.5.0 pyparsing-3.0.7 python-dateutil-2.8.2 pytorch_lightning-1.4.8 pytz-2022.1 pyyaml-6.0 regex-2022.3.15 requests-oauthlib-1.3.1 rsa-4.8 sacremoses-0.0.49 smart-open-5.2.1 smmap-5.0.0 spacy-3.1.3 spacy-legacy-3.0.9 srsly-2.4.2 tabulate-0.8.9 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 thinc-8.0.15 tokenizers-0.10.3 torch-1.8.0 torchmetrics-0.5.1 transformers-4.11.0 typer-0.4.1 typing-extensions-3.10.0.2 wasabi-0.9.1 websocket-client-1.3.2 werkzeug-2.1.1 yarl-1.7.2 zipp-3.8.0\n",
            "\b\b/ \n",
            "\b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate base\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_bIvrvkM1Mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87264c92-7043-417a-95e6-53c60d4441d3"
      },
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ğŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZPIh8_wM1tf"
      },
      "source": [
        "import pytorch_lightning\n",
        "from azureml.core.authentication import ServicePrincipalAuthentication"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.cli import download\n",
        "\n",
        "download(\"en_core_web_sm\")\n",
        "#python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V2WGAi2qlBY",
        "outputId": "d44f3de8-9472-426a-fab8-19407468244c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opPtU3B0NVdT"
      },
      "source": [
        "# Local Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITNg1N6qMclD"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tHFHj_vDVGt"
      },
      "source": [
        "Open IMDB dataset and explore some example sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy.data import Field\n",
        "from torchtext.legacy.datasets import IMDB\n",
        "import torch\n",
        "\n",
        "#dir(Field)\n",
        "#Field.dtypes\n",
        "\n",
        "import spacy\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "wn_W63WrfQc1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLAaSuSpMclI"
      },
      "source": [
        "from torchtext.legacy.data import Field\n",
        "from torchtext.legacy.datasets import IMDB\n",
        "import torch\n",
        "\n",
        "# Create a simple Field just to be able to read sentences and labels\n",
        "text = Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\")\n",
        "label = Field(dtype=torch.float)\n",
        "train, test = IMDB.splits(text, label)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTuce1GDt5l"
      },
      "source": [
        "Explore data, look at a few sentences in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ww72OlgLttf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a92fb29-e2c9-4157-b126-1e6f97023328"
      },
      "source": [
        "print(f'Number of training examples: {len(train)}')\n",
        "print(f'Number of testing examples: {len(test)}')\n",
        "print(vars(train.examples[1]))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n",
            "{'text': ['I', 'was', 'so', 'glad', 'I', 'came', 'across', 'this', 'short', 'film', '.', 'I', \"'m\", 'always', 'so', 'disappointed', 'that', 'short', 'films', 'are', 'hard', 'to', 'come', 'across', ',', 'so', 'when', 'I', 'saw', 'this', 'and', 'saw', 'that', 'it', 'was', 'nominated', 'for', 'the', 'Live', 'Action', 'Short', 'Film', 'at', 'the', 'Academy', 'Awards', ',', 'I', 'was', 'so', 'pleased', 'that', 'I', 'actually', 'had', 'a', 'film', 'that', 'I', 'was', 'rooting', 'for.<br', '/><br', '/>The', 'plot', 'is', 'pretty', 'simple', ',', 'the', 'director', ',', 'writer', ',', 'and', 'star', 'Nacho', 'Vigalondo', 'tried', 'coming', 'up', 'with', 'a', 'reason', 'people', 'would', 'suddenly', 'break', 'out', 'into', 'a', 'song', 'and', 'dance', 'number', 'like', 'they', 'do', 'in', 'movie', 'musicals', '.', 'The', 'result', 'is', 'extremely', 'entertaining', 'and', 'the', 'song', 'is', 'actually', 'really', 'catchy.<br', '/><br', '/>It', \"'s\", 'a', 'well', 'made', 'short', 'film', ',', 'well', 'edited', 'and', 'the', 'actors', 'all', 'do', 'a', 'great', 'job', '.', 'And', 'the', 'last', 'shot', 'of', 'the', 'film', 'is', 'perfect.<br', '/><br', '/>I', 'highly', 'recommend', 'this', 'film', '.'], 'label': ['pos']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAYARaxpMclK"
      },
      "source": [
        "## Data Prepration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vU9XlNCETG_"
      },
      "source": [
        "Write code to tokenize sentences, print a few sample sentences and their tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d20vG1C1Ef4n"
      },
      "source": [
        "# Write code\n",
        "def generate_bigrams(x):\n",
        "    n_grams = set(zip(*[x[i:] for i in range(2)]))\n",
        "    for n_gram in n_grams:\n",
        "        x.append(' '.join(n_gram))\n",
        "    return x\n",
        "\n",
        "def tokenizer(text):\n",
        "    return [token.text for token in spacy_en.tokenizer(text)]\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjyhQPh4MclM"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQOPv7wPEtjc"
      },
      "source": [
        "Write code to tokenize and preprocess data in dataset, split data into train, val and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DfOp0lmE8xa"
      },
      "source": [
        "# Write code\n",
        "import random\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "text = Field(tokenize='spacy', tokenizer_language=\"en_core_web_sm\", preprocessing=generate_bigrams)\n",
        "#label = Field(dtype=torch.float)\n",
        "label = data.LabelField(dtype = torch.float)\n",
        "train, test = IMDB.splits(text, label)\n",
        "\n",
        "train_data, valid_data = train.split(split_ratio = 0.8, random_state = random.seed(SEED))\n",
        "\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "text.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "label.build_vocab(train_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(valid_data)}')\n",
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYQxGWdVwHfD",
        "outputId": "8bd2726d-27b3-4ff0-de3a-a4d36df3dac8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 20000\n",
            "Number of testing examples: 5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Dataset.__getattr__ at 0x7f9693a7df50>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26iexRI5MclO"
      },
      "source": [
        "## Model Implementation\n",
        "\n",
        "Write code to create a model for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBCpPxMIFNQf"
      },
      "source": [
        "# Write code\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FastSentimentAnalyzer(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, output_dim, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        \n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "                \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "        \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
        "        \n",
        "        #pooled = [batch size, embedding_dim]\n",
        "                \n",
        "        return self.fc(pooled)\n",
        "\n",
        "\n",
        "class RNNSentimentAnalyzer(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        \n",
        "        return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPNzUOATMclQ"
      },
      "source": [
        "## Training\n",
        "\n",
        "Write code to train your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3QSCA7bMclQ"
      },
      "source": [
        "# Write code\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)    \n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Training"
      ],
      "metadata": {
        "id": "-HtMFo1g0xhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.legacy import data\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "model = FastSentimentAnalyzer(INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, PAD_IDX)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)\n",
        "\n",
        "INPUT_DIM = len(text.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "PAD_IDX = text.vocab.stoi[text.pad_token]\n",
        "\n",
        "pretrained_embeddings = text.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "UNK_IDX = text.vocab.stoi[text.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "u_j_EMAg0zob",
        "outputId": "c6a5eabd-a6d7-4010-becd-6c61adbca35c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-b6187bb489b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-6a025d663bc4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1, 64])) must be the same as input size (torch.Size([64]))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a0erkdENf7F"
      },
      "source": [
        "# Azure ML Backed Hyper Experimention (OPTIONAL)\n",
        "\n",
        "You do not need to complete the following sections, but if you are feeling brave go ahead.  You will need to setup your own Azure subscription, resource group, and AzureML Workspace (with compute clusters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vb3h7S_PNp9R"
      },
      "source": [
        "## Azure Workspace Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U1AtAyHbWV0"
      },
      "source": [
        "### Service Prinicple Auth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99MBTe-7Ni4f"
      },
      "source": [
        "from azureml.core.authentication import ServicePrincipalAuthentication\n",
        "from azureml.core import Workspace\n",
        "\n",
        "sp = ServicePrincipalAuthentication(tenant_id=\"<tenant_id>\", # tenantID\n",
        "                                    service_principal_id=\"<client_id>\", # clientId\n",
        "                                    service_principal_password=\"<pass>\")\n",
        "\n",
        "subscription_id = \"<sub_id>\"\n",
        "resource_group = \"<resource_group>\"\n",
        "workspace_name = '<ws_name>'\n",
        "\n",
        "ws = Workspace.get(subscription_id=subscription_id, resource_group=resource_group, name=workspace_name, auth=sp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEdp2xC5bSy-"
      },
      "source": [
        "## Environment Auth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrtSzXl4bQX4"
      },
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "subscription_id = \"<sub_id>\"\n",
        "resource_group = \"<resource_group>\"\n",
        "workspace_name = '<ws_name>'\n",
        "\n",
        "ws = Workspace(subscription_id, resource_group, workspace_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBQFDzhCbmeo"
      },
      "source": [
        "## Run on AzureML\n",
        "\n",
        "Write code to generate a single run, optionally include hyperdrive run\n",
        "\n",
        "[Here is a helpful tutorial](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/ml-frameworks/pytorch/train-hyperparameter-tune-deploy-with-pytorch/train-hyperparameter-tune-deploy-with-pytorch.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-2JkbzQHfaS"
      },
      "source": [
        "# Write code"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}